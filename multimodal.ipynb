{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "import os\n",
    "from transformers import AutoModel  # Electra, BERT 모델을 동적으로 불러오기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "books_df = pd.read_csv('../../data/books.csv')\n",
    "users_df = pd.read_csv('../../data/users.csv')\n",
    "train_ratings_df = pd.read_csv('../../data/train_ratings.csv')\n",
    "test_ratings_df = pd.read_csv('../../data/test_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['age'] = pd.to_numeric(users_df['age'], errors='coerce')\n",
    "median_age = users_df['age'].median()\n",
    "users_df['age'] = users_df['age'].fillna(median_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['year_of_publication'] = pd.to_numeric(books_df['year_of_publication'], errors='coerce')\n",
    "median_year = books_df['year_of_publication'].median()\n",
    "books_df['year_of_publication'] = books_df['year_of_publication'].fillna(median_year).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 병합\n",
    "train_data = train_ratings_df.merge(books_df, on='isbn').merge(users_df, on='user_id')\n",
    "test_data = test_ratings_df.merge(books_df, on='isbn').merge(users_df, on='user_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User의 평균 평점 계산\n",
    "user_avg_rating = train_data.groupby('user_id')['rating'].mean().reset_index(name='user_mean_rating')\n",
    "\n",
    "# Book의 평균 평점 계산\n",
    "book_avg_rating = train_data.groupby('isbn')['rating'].mean().reset_index(name='book_mean_rating')\n",
    "\n",
    "# 원래 데이터프레임에 user와 book의 평균 평점 합치기\n",
    "train_data = train_data.merge(user_avg_rating, on='user_id')\n",
    "train_data = train_data.merge(book_avg_rating, on='isbn')\n",
    "\n",
    "# 테스트 데이터에 훈련 데이터의 평균 평점 적용\n",
    "test_data = test_data.merge(user_avg_rating, on='user_id', how='left')\n",
    "test_data = test_data.merge(book_avg_rating, on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data와 test_data에 country 컬럼 추가\n",
    "train_data['country'] = train_data['location'].apply(lambda x: x.split(',')[-1].strip())\n",
    "test_data['country'] = test_data['location'].apply(lambda x: x.split(',')[-1].strip())\n",
    "\n",
    "# train_data에서 Target Encoding 값 계산\n",
    "target_encoding_map = train_data.groupby('country')['rating'].mean().to_dict()\n",
    "train_data['country_encoded'] = train_data['country'].map(target_encoding_map)\n",
    "\n",
    "# test_data에 적용\n",
    "global_mean = train_data['rating'].mean()\n",
    "test_data['country_encoded'] = test_data['country'].map(target_encoding_map).fillna(global_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 결측치 처리 \n",
    "train_data['book_author'] = train_data['book_author'].fillna(' ')\n",
    "train_data['summary'] = train_data['summary'].fillna(' ')\n",
    "test_data['book_author'] = test_data['book_author'].fillna(' ')\n",
    "test_data['summary'] = test_data['summary'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 결측치 처리 \n",
    "test_data['user_mean_rating'] = test_data['user_mean_rating'].fillna(test_data['user_mean_rating'].mean())\n",
    "test_data['book_mean_rating'] = test_data['book_mean_rating'].fillna(test_data['book_mean_rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 특징 선택\n",
    "features = ['user_id', 'isbn', 'book_title', 'book_author', 'year_of_publication', 'publisher', \n",
    "            'age', 'img_path', 'summary', 'user_mean_rating', 'book_mean_rating', 'country_encoded']\n",
    "train_data = train_data[features + ['rating']]\n",
    "test_data = test_data[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 텍스트 전처리를 위한 토크나이저 초기화\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Electra에 맞는 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리를 위한 변환 정의\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 \n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['year_of_publication', 'age', 'user_mean_rating', 'book_mean_rating']\n",
    "train_data[numerical_features] = scaler.fit_transform(train_data[numerical_features])\n",
    "test_data[numerical_features] = scaler.transform(test_data[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDN 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide & Deep Network 모델 구현\n",
    "class WideAndDeepModel(nn.Module):\n",
    "    def __init__(self, num_numerical_features, text_model_name=\"google/electra-small-discriminator\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Wide 파트 (단순 합산)\n",
    "        self.wide = nn.Linear(num_numerical_features, 1)\n",
    "\n",
    "        # Deep 파트 - 이미지 인코더\n",
    "        self.image_encoder = models.resnet18(pretrained=True)\n",
    "        self.image_encoder.fc = nn.Linear(self.image_encoder.fc.in_features, 128)\n",
    "        \n",
    "        # Deep 파트 - 텍스트 인코더\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
    "        text_embedding_dim = 256 if \"electra\" in text_model_name else 768\n",
    "        self.text_fc = nn.Linear(text_embedding_dim, 128)\n",
    "        \n",
    "        # Deep 파트 - 정형 데이터 인코더\n",
    "        self.numerical_encoder = nn.Sequential(\n",
    "            nn.Linear(num_numerical_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "        \n",
    "        # Deep 파트 - 퓨전\n",
    "        self.deep_fusion = nn.Sequential(\n",
    "            nn.Linear(128 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Wide와 Deep 결합을 위한 최종 예측 층\n",
    "        self.final_layer = nn.Linear(128 + 1, 1)\n",
    "\n",
    "    def forward(self, image, text_ids, text_mask, numerical_features, wide_features):\n",
    "        # Wide 파트 출력\n",
    "        y_wide = self.wide(wide_features).squeeze(1)\n",
    "        \n",
    "        # Deep 파트 - 이미지 인코딩\n",
    "        image_features = self.image_encoder(image)\n",
    "        \n",
    "        # Deep 파트 - 텍스트 인코딩\n",
    "        text_output = self.text_encoder(input_ids=text_ids, attention_mask=text_mask)\n",
    "        if hasattr(text_output, \"pooler_output\"):\n",
    "            text_features = self.text_fc(text_output.pooler_output)\n",
    "        else:\n",
    "            text_features = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        # Deep 파트 - 정형 데이터 인코딩\n",
    "        numerical_features = self.numerical_encoder(numerical_features)\n",
    "        \n",
    "        # Deep 파트 - 이미지, 텍스트, 정형 데이터 특징 결합\n",
    "        combined_features = torch.cat([image_features, text_features, numerical_features], dim=1)\n",
    "        y_deep = self.deep_fusion(combined_features)\n",
    "\n",
    "        # Wide와 Deep 출력 결합\n",
    "        # final_features = torch.cat([y_wide, y_deep], dim=1)\n",
    "        # rating = self.final_layer(final_features)\n",
    "        # Wide와 Deep 출력 결합\n",
    "        final_features = torch.cat([y_wide.unsqueeze(1), y_deep], dim=1)\n",
    "        rating = self.final_layer(final_features)\n",
    "\n",
    "        \n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class BookDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, numerical_features, max_length=128):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.numerical_features = numerical_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # 텍스트 처리\n",
    "        text = f\"{row['book_title']} {row['book_author']} {row['summary']}\"\n",
    "\n",
    "        text = ' '.join([str(item) if pd.notna(item) else '' for item in text.split()])\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        # 이미지 처리\n",
    "        # 이미지 경로 설정 시 중복되는 'images/' 부분 제거\n",
    "        image_filename = row['img_path'].replace('images/', '')  # 'images/' 부분 제거\n",
    "        image_path = os.path.join('/data/ephemeral/home/data/images', image_filename)\n",
    "        #image_path = os.path.join('/data/ephemeral/home/data/images', row['img_path'])\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image_transform(image)\n",
    "\n",
    "        # 수치형 특징\n",
    "        # numerical = torch.tensor([row[feature] for feature in numerical_features], dtype=torch.float)\n",
    "        numerical = torch.tensor([row[feature] for feature in self.numerical_features], dtype=torch.float)\n",
    "\n",
    "\n",
    "        # 레이블 (학습 데이터의 경우)\n",
    "        if 'rating' in row:\n",
    "            label = torch.tensor(row['rating'], dtype=torch.float)\n",
    "        else:\n",
    "            label = torch.tensor(0, dtype=torch.float)  # 테스트 데이터의 경우 더미 값\n",
    "\n",
    "        return {\n",
    "            'text_ids': encoding['input_ids'].flatten(),\n",
    "            'text_mask': encoding['attention_mask'].flatten(),\n",
    "            'image': image,\n",
    "            'numerical': numerical,\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_1, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = BookDataset(train_data, tokenizer)\n",
    "# val_dataset = BookDataset(val_data, tokenizer)\n",
    "# test_dataset = BookDataset(test_data, tokenizer)\n",
    "\n",
    "train_dataset = BookDataset(train_data, tokenizer, numerical_features=numerical_features)\n",
    "val_dataset = BookDataset(val_data, tokenizer, numerical_features=numerical_features)\n",
    "test_dataset = BookDataset(test_data, tokenizer, numerical_features=numerical_features)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalBookRatingModel(nn.Module):\n",
    "    def __init__(self, num_numerical_features, text_model_name=\"google/electra-small-discriminator\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 이미지 인코더\n",
    "        self.image_encoder = models.resnet18(pretrained=True)\n",
    "        self.image_encoder.fc = nn.Linear(self.image_encoder.fc.in_features, 128)\n",
    "        \n",
    "        # 텍스트 인코더\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
    "        \n",
    "        # 텍스트 임베딩 차원을 모델에 따라 동적으로 설정\n",
    "        text_embedding_dim = 256 if \"electra\" in text_model_name else 768\n",
    "        self.text_fc = nn.Linear(text_embedding_dim, 128)\n",
    "        \n",
    "        # 정형 데이터 인코더\n",
    "        self.numerical_encoder = nn.Sequential(\n",
    "            nn.Linear(num_numerical_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "        \n",
    "        # 멀티모달 퓨전\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(128 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, text_ids, text_mask, numerical_features):\n",
    "        # 이미지 인코딩\n",
    "        image_features = self.image_encoder(image)\n",
    "        \n",
    "        # 텍스트 인코딩\n",
    "        text_output = self.text_encoder(input_ids=text_ids, attention_mask=text_mask)\n",
    "        \n",
    "        # Electra와 BERT 모델을 구분하여 텍스트 임베딩 생성\n",
    "        if hasattr(text_output, \"pooler_output\"):\n",
    "            text_features = self.text_fc(text_output.pooler_output)\n",
    "        else:\n",
    "            text_features = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        # 정형 데이터 인코딩\n",
    "        numerical_features = self.numerical_encoder(numerical_features)\n",
    "        \n",
    "        # 특징 결합\n",
    "        combined_features = torch.cat([image_features, text_features, numerical_features], dim=1)\n",
    "        \n",
    "        # 평점 예측\n",
    "        rating = self.fusion(combined_features)\n",
    "        \n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WDN / 2-layer MLP 중 하나 선택하여 model 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "# model = MultimodalBookRatingModel(num_numerical_features=len(numerical_features)) # WDN 아닌 기존 2-layer MLP \n",
    "model = WideAndDeepModel(num_numerical_features=len(numerical_features)) # WDN\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WDN / 2-layer MLP 중 하나 선택하여 model 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text_ids = batch['text_ids'].to(device)\n",
    "        text_mask = batch['text_mask'].to(device)\n",
    "        image = batch['image'].to(device)\n",
    "        numerical = batch['numerical'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # wide_features를 numerical로 전달\n",
    "        # outputs = model(image, text_ids, text_mask, numerical) # WDN 이 아닌 기존 Multimodal을 사용할 경우 \n",
    "        outputs = model(image, text_ids, text_mask, numerical, wide_features=numerical) # WDN\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            text_ids = batch['text_ids'].to(device)\n",
    "            text_mask = batch['text_mask'].to(device)\n",
    "            image = batch['image'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # wide_features를 numerical로 전달\n",
    "            # outputs = model(image, text_ids, text_mask, numerical) # WDN 이 아닌 기존 Multimodal\n",
    "            outputs = model(image, text_ids, text_mask, numerical, wide_features=numerical) # WDN\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 예측\n",
    "model.eval()\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        text_ids = batch['text_ids'].to(device)\n",
    "        text_mask = batch['text_mask'].to(device)\n",
    "        image = batch['image'].to(device)\n",
    "        numerical = batch['numerical'].to(device)\n",
    "        \n",
    "        # outputs = model(image, text_ids, text_mask, numerical) # WDN 이 아닌 기존 Multimodal\n",
    "        outputs = model(image, text_ids, text_mask, numerical, wide_features=numerical) # WDN\n",
    "        predictions.extend(outputs.cpu().numpy()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 테스트 데이터프레임에 추가\n",
    "test_data['rating'] = predictions\n",
    "test_data['rating'] = test_data['rating'].fillna(test_data['rating'].mean()) # 결측치는 평균값으로 보간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "submission = test_data[['user_id', 'isbn', 'rating']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"예측이 완료되었습니다. 결과는 'submission.csv' 파일에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
