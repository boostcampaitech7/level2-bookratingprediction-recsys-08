{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "books_df = pd.read_csv('../../data/books.csv')\n",
    "users_df = pd.read_csv('../../data/users.csv')\n",
    "train_ratings_df = pd.read_csv('../../data/train_ratings.csv')\n",
    "test_ratings_df = pd.read_csv('../../data/test_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['age'] = pd.to_numeric(users_df['age'], errors='coerce')\n",
    "median_age = users_df['age'].median()\n",
    "users_df['age'] = users_df['age'].fillna(median_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['year_of_publication'] = pd.to_numeric(books_df['year_of_publication'], errors='coerce')\n",
    "median_year = books_df['year_of_publication'].median()\n",
    "books_df['year_of_publication'] = books_df['year_of_publication'].fillna(median_year).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 병합\n",
    "train_data = train_ratings_df.merge(books_df, on='isbn').merge(users_df, on='user_id')\n",
    "test_data = test_ratings_df.merge(books_df, on='isbn').merge(users_df, on='user_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User의 평균 평점 계산\n",
    "user_avg_rating = train_data.groupby('user_id')['rating'].mean().reset_index(name='user_mean_rating')\n",
    "\n",
    "# Book의 평균 평점 계산\n",
    "book_avg_rating = train_data.groupby('isbn')['rating'].mean().reset_index(name='book_mean_rating')\n",
    "\n",
    "# 원래 데이터프레임에 user와 book의 평균 평점 합치기\n",
    "train_data = train_data.merge(user_avg_rating, on='user_id')\n",
    "train_data = train_data.merge(book_avg_rating, on='isbn')\n",
    "\n",
    "# 테스트 데이터에 훈련 데이터의 평균 평점 적용\n",
    "test_data = test_data.merge(user_avg_rating, on='user_id', how='left')\n",
    "test_data = test_data.merge(book_avg_rating, on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>user_mean_rating</th>\n",
       "      <th>book_mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>6.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67544</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>7</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>6.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123629</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>kingston, ontario, canada</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200273</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>comber, ontario, canada</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210926</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>9</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Actresses']</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>guelph, ontario, canada</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>6.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306790</th>\n",
       "      <td>278843</td>\n",
       "      <td>0743525493</td>\n",
       "      <td>7</td>\n",
       "      <td>The Motley Fool's What To Do with Your Money N...</td>\n",
       "      <td>David Gardner</td>\n",
       "      <td>2002</td>\n",
       "      <td>Simon &amp; Schuster Audio</td>\n",
       "      <td>http://images.amazon.com/images/P/0743525493.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0743525493.01.THUMBZZZ.jpg</td>\n",
       "      <td>pismo beach, california, usa</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306791</th>\n",
       "      <td>278851</td>\n",
       "      <td>067161746X</td>\n",
       "      <td>6</td>\n",
       "      <td>The Bachelor Home Companion: A Practical Guide...</td>\n",
       "      <td>P.J. O'Rourke</td>\n",
       "      <td>1987</td>\n",
       "      <td>Pocket Books</td>\n",
       "      <td>http://images.amazon.com/images/P/067161746X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Humor']</td>\n",
       "      <td>A tongue-in-cheek survival guide for single pe...</td>\n",
       "      <td>images/067161746X.01.THUMBZZZ.jpg</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306792</th>\n",
       "      <td>278851</td>\n",
       "      <td>0884159221</td>\n",
       "      <td>7</td>\n",
       "      <td>Why stop?: A guide to Texas historical roadsid...</td>\n",
       "      <td>Claude Dooley</td>\n",
       "      <td>1985</td>\n",
       "      <td>Lone Star Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0884159221.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0884159221.01.THUMBZZZ.jpg</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306793</th>\n",
       "      <td>278851</td>\n",
       "      <td>0912333022</td>\n",
       "      <td>7</td>\n",
       "      <td>The Are You Being Served? Stories: 'Camping In...</td>\n",
       "      <td>Jeremy Lloyd</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kqed Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0912333022.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>These hilarious stories by the creator of publ...</td>\n",
       "      <td>images/0912333022.01.THUMBZZZ.jpg</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306794</th>\n",
       "      <td>278851</td>\n",
       "      <td>1569661057</td>\n",
       "      <td>10</td>\n",
       "      <td>Dallas Street Map Guide and Directory, 2000 Ed...</td>\n",
       "      <td>Mapsco</td>\n",
       "      <td>1999</td>\n",
       "      <td>American Map Corporation</td>\n",
       "      <td>http://images.amazon.com/images/P/1569661057.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1569661057.01.THUMBZZZ.jpg</td>\n",
       "      <td>dallas, texas, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306795 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn  rating  \\\n",
       "0             8  0002005018       4   \n",
       "1         67544  0002005018       7   \n",
       "2        123629  0002005018       8   \n",
       "3        200273  0002005018       8   \n",
       "4        210926  0002005018       9   \n",
       "...         ...         ...     ...   \n",
       "306790   278843  0743525493       7   \n",
       "306791   278851  067161746X       6   \n",
       "306792   278851  0884159221       7   \n",
       "306793   278851  0912333022       7   \n",
       "306794   278851  1569661057      10   \n",
       "\n",
       "                                               book_title  \\\n",
       "0                                            Clara Callan   \n",
       "1                                            Clara Callan   \n",
       "2                                            Clara Callan   \n",
       "3                                            Clara Callan   \n",
       "4                                            Clara Callan   \n",
       "...                                                   ...   \n",
       "306790  The Motley Fool's What To Do with Your Money N...   \n",
       "306791  The Bachelor Home Companion: A Practical Guide...   \n",
       "306792  Why stop?: A guide to Texas historical roadsid...   \n",
       "306793  The Are You Being Served? Stories: 'Camping In...   \n",
       "306794  Dallas Street Map Guide and Directory, 2000 Ed...   \n",
       "\n",
       "                 book_author  year_of_publication                 publisher  \\\n",
       "0       Richard Bruce Wright                 2001     HarperFlamingo Canada   \n",
       "1       Richard Bruce Wright                 2001     HarperFlamingo Canada   \n",
       "2       Richard Bruce Wright                 2001     HarperFlamingo Canada   \n",
       "3       Richard Bruce Wright                 2001     HarperFlamingo Canada   \n",
       "4       Richard Bruce Wright                 2001     HarperFlamingo Canada   \n",
       "...                      ...                  ...                       ...   \n",
       "306790         David Gardner                 2002    Simon & Schuster Audio   \n",
       "306791         P.J. O'Rourke                 1987              Pocket Books   \n",
       "306792         Claude Dooley                 1985           Lone Star Books   \n",
       "306793          Jeremy Lloyd                 1997                Kqed Books   \n",
       "306794                Mapsco                 1999  American Map Corporation   \n",
       "\n",
       "                                                  img_url language  \\\n",
       "0       http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "2       http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "3       http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "4       http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "...                                                   ...      ...   \n",
       "306790  http://images.amazon.com/images/P/0743525493.0...      NaN   \n",
       "306791  http://images.amazon.com/images/P/067161746X.0...       en   \n",
       "306792  http://images.amazon.com/images/P/0884159221.0...      NaN   \n",
       "306793  http://images.amazon.com/images/P/0912333022.0...       en   \n",
       "306794  http://images.amazon.com/images/P/1569661057.0...      NaN   \n",
       "\n",
       "             category                                            summary  \\\n",
       "0       ['Actresses']  In a small town in Canada, Clara Callan reluct...   \n",
       "1       ['Actresses']  In a small town in Canada, Clara Callan reluct...   \n",
       "2       ['Actresses']  In a small town in Canada, Clara Callan reluct...   \n",
       "3       ['Actresses']  In a small town in Canada, Clara Callan reluct...   \n",
       "4       ['Actresses']  In a small town in Canada, Clara Callan reluct...   \n",
       "...               ...                                                ...   \n",
       "306790            NaN                                                NaN   \n",
       "306791      ['Humor']  A tongue-in-cheek survival guide for single pe...   \n",
       "306792            NaN                                                NaN   \n",
       "306793    ['Fiction']  These hilarious stories by the creator of publ...   \n",
       "306794            NaN                                                NaN   \n",
       "\n",
       "                                 img_path                      location   age  \\\n",
       "0       images/0002005018.01.THUMBZZZ.jpg      timmins, ontario, canada  34.0   \n",
       "1       images/0002005018.01.THUMBZZZ.jpg      toronto, ontario, canada  30.0   \n",
       "2       images/0002005018.01.THUMBZZZ.jpg     kingston, ontario, canada  34.0   \n",
       "3       images/0002005018.01.THUMBZZZ.jpg       comber, ontario, canada  34.0   \n",
       "4       images/0002005018.01.THUMBZZZ.jpg       guelph, ontario, canada  34.0   \n",
       "...                                   ...                           ...   ...   \n",
       "306790  images/0743525493.01.THUMBZZZ.jpg  pismo beach, california, usa  28.0   \n",
       "306791  images/067161746X.01.THUMBZZZ.jpg            dallas, texas, usa  33.0   \n",
       "306792  images/0884159221.01.THUMBZZZ.jpg            dallas, texas, usa  33.0   \n",
       "306793  images/0912333022.01.THUMBZZZ.jpg            dallas, texas, usa  33.0   \n",
       "306794  images/1569661057.01.THUMBZZZ.jpg            dallas, texas, usa  33.0   \n",
       "\n",
       "        user_mean_rating  book_mean_rating  \n",
       "0               4.428571          6.857143  \n",
       "1               7.285714          6.857143  \n",
       "2               8.000000          6.857143  \n",
       "3               8.000000          6.857143  \n",
       "4               8.400000          6.857143  \n",
       "...                  ...               ...  \n",
       "306790          8.000000          7.000000  \n",
       "306791          5.833333          6.000000  \n",
       "306792          5.833333          7.000000  \n",
       "306793          5.833333          7.000000  \n",
       "306794          5.833333         10.000000  \n",
       "\n",
       "[306795 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 특징 선택\n",
    "features = ['user_id', 'isbn', 'book_title', 'book_author', 'year_of_publication', 'publisher', \n",
    "            'age', 'img_path', 'summary', 'user_mean_rating', 'book_mean_rating']\n",
    "train_data = train_data[features + ['rating']]\n",
    "test_data = test_data[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리를 위한 토크나이저 초기화\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리를 위한 변환 정의\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_715584/1826618647.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[numerical_features] = scaler.fit_transform(train_data[numerical_features])\n"
     ]
    }
   ],
   "source": [
    "# 정규화 \n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['year_of_publication', 'age', 'user_mean_rating', 'book_mean_rating']\n",
    "train_data[numerical_features] = scaler.fit_transform(train_data[numerical_features])\n",
    "test_data[numerical_features] = scaler.transform(test_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class BookDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # 텍스트 처리\n",
    "        text = f\"{row['book_title']} {row['book_author']} {row['summary']}\"\n",
    "\n",
    "        text = ' '.join([str(item) if pd.notna(item) else '' for item in text.split()])\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        # 이미지 처리\n",
    "        # 이미지 경로 설정 시 중복되는 'images/' 부분 제거\n",
    "        image_filename = row['img_path'].replace('images/', '')  # 'images/' 부분 제거\n",
    "        image_path = os.path.join('/data/ephemeral/home/data/images', image_filename)\n",
    "        #image_path = os.path.join('/data/ephemeral/home/data/images', row['img_path'])\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image_transform(image)\n",
    "\n",
    "        # 수치형 특징\n",
    "        numerical = torch.tensor([row[feature] for feature in numerical_features], dtype=torch.float)\n",
    "\n",
    "        # 레이블 (학습 데이터의 경우)\n",
    "        if 'rating' in row:\n",
    "            label = torch.tensor(row['rating'], dtype=torch.float)\n",
    "        else:\n",
    "            label = torch.tensor(0, dtype=torch.float)  # 테스트 데이터의 경우 더미 값\n",
    "\n",
    "        return {\n",
    "            'text_ids': encoding['input_ids'].flatten(),\n",
    "            'text_mask': encoding['attention_mask'].flatten(),\n",
    "            'image': image,\n",
    "            'numerical': numerical,\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_1, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BookDataset(train_data, tokenizer)\n",
    "val_dataset = BookDataset(val_data, tokenizer)\n",
    "test_dataset = BookDataset(test_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultimodalBookRatingModel(nn.Module):\n",
    "    def __init__(self, num_numerical_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 이미지 인코더\n",
    "        self.image_encoder = models.resnet18(pretrained=True)\n",
    "        self.image_encoder.fc = nn.Linear(self.image_encoder.fc.in_features, 128)\n",
    "        \n",
    "        # 텍스트 인코더\n",
    "        self.text_encoder = BertModel.from_pretrained(\"google/electra-small-discriminator\") # 기존: 'bert-base-uncased'\n",
    "        self.text_fc = nn.Linear(768, 128)\n",
    "        \n",
    "        # 정형 데이터 인코더\n",
    "        self.numerical_encoder = nn.Sequential(\n",
    "            nn.Linear(num_numerical_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "        \n",
    "        # 멀티모달 퓨전\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(128 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, text_ids, text_mask, numerical_features):\n",
    "        # 이미지 인코딩\n",
    "        image_features = self.image_encoder(image)\n",
    "        \n",
    "        # 텍스트 인코딩\n",
    "        text_output = self.text_encoder(input_ids=text_ids, attention_mask=text_mask)\n",
    "        text_features = self.text_fc(text_output.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        # 정형 데이터 인코딩\n",
    "        numerical_features = self.numerical_encoder(numerical_features)\n",
    "        \n",
    "        # 특징 결합\n",
    "        combined_features = torch.cat([image_features, text_features, numerical_features], dim=1)\n",
    "        \n",
    "        # 평점 예측\n",
    "        rating = self.fusion(combined_features)\n",
    "        \n",
    "        return rating.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = MultimodalBookRatingModel(num_numerical_features=len(numerical_features))\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text_ids = batch['text_ids'].to(device)\n",
    "        text_mask = batch['text_mask'].to(device)\n",
    "        image = batch['image'].to(device)\n",
    "        numerical = batch['numerical'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(image, text_ids, text_mask, numerical)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            text_ids = batch['text_ids'].to(device)\n",
    "            text_mask = batch['text_mask'].to(device)\n",
    "            image = batch['image'].to(device)\n",
    "            numerical = batch['numerical'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(image, text_ids, text_mask, numerical)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[39m=\u001b[39m train_epoch(model, train_loader, criterion, optimizer, device)\n\u001b[1;32m      7\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, val_loader, criterion, device)\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[38], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 20\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측이 완료되었습니다. 결과는 'submission.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 예측\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        text_ids = batch['text_ids'].to(device)\n",
    "        text_mask = batch['text_mask'].to(device)\n",
    "        image = batch['image'].to(device)\n",
    "        numerical = batch['numerical'].to(device)\n",
    "        \n",
    "        outputs = model(image, text_ids, text_mask, numerical)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "# 예측 결과를 테스트 데이터프레임에 추가\n",
    "test_data['rating'] = predictions\n",
    "\n",
    "# 결과 저장\n",
    "submission = test_data[['user_id', 'isbn', 'predicted_rating']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"예측이 완료되었습니다. 결과는 'submission.csv' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
